---
title: "R Guide"
subtitle: für das Neurolinguistics Lab Mainz
date: 'Stand: 31.01.2021'
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    number_sections: yes
---

To-do: 

- Stepwise Regression & Pairwise Comparison überarbeiten    
- (automatische Signifkanzssterne in Plots)   
- (Generalized Linear Mixed Effects Models)   
- (Bayesian methods)    
- (interaktive Aufgaben)    

***
Bei Fragen, Verbesserungsvorschlägen und Anregungen gerne an <josh.ziegler@icloud.com> wenden.

***

**Was ist R?** 

> *R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of UNIX platforms, Windows and MacOS.* (Quelle: <https://www.r-project.org>)

**Wie installiere ich R?**    
R kann kostenlos über das [Comprehensive R Archive Network (CRAN)](https://cran.r-project.org/mirrors.html) heruntergeladen und anschließend installiert werden.

**Wie installiere ich RStudio (ein beliebtes GUI für R)?**    
Rstudio ist ein Graphic User Interface (GUI) für R, welches die Arbeit mit R übersichtlicher machen kann. Es kann kostenlos von der [RStudio Homepage](https://rstudio.com/products/rstudio/download/) heruntergeladen und anschließend installiert werden.

**Was sind Pakete (*packages*)?**   
Pakete sind Erweiterungen für R, die sich direkt über die Konsole installieren und laden lassen. Sie beinhalten z.B. neue Funktionen, überarbeitete Funktionen oder auch Datensätze und ergänzen somit R um die vorinstallierten Funktionen (= *baseR*). 

**Wie lerne ich R?**    
Um R zu lernen gibt es viele Resourcen. Ich empfehle das Paket **swirl**, da es direkt innerhalb RStudio durchgeführt werden kann. Um das Tutorial zu starten müssen folgende Schritte in der *Console* ausgeführt werden:

1. Das Paket "swirl" installieren: ```install.packages("swirl")```  
2. Das Paket "swirl" laden: ```library(swirl)```  
3. Die Funktion swirl() ausführen: ```swirl()``` 

swirl leitet dann innerhalb der *Console* durch die Tutorials.    

Des Weiteren empfielt es sich, die eigenen R-Projekte so zu organisieren, dass sie auch nach langer Zeit noch ersichtlich sind. Neben eindeutigen Benennungen von Variablen, Daten, Plots, etc. lohnt es sich vor allem eine gute Ordnerstruktur anzulegen. Hilfreiche Links dazu:     

- RStudio [Projects](https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects)
- Version Control: [GitHub & RStudio Guide von Jennifer Bryan](https://happygitwithr.com/big-picture.html)

**Was ist ein R Markdown?**   
R Markdown ermöglicht es, Code in einer schriftlichen Arbeit zu integrieren. Der Code befindet sich in sogenannten "Chunks", die sich in RStudio direkt in der Datei ausführen lassen. Das ganze Dokument, inklusive Code und Output, lässt sich unter Anderem als html- oder pdf-Datei exportieren. Mehr Informationen gibt es auf der [offiziellen Website](https://rmarkdown.rstudio.com/lesson-1.html).

R Markdown verfügt über viele gestalterische Optionen. Ein Cheatsheet lässt sich in RStudio wie folgt aufrufen:   
*Help > Cheatsheets > R Markdown Cheat Sheet*

**Wie werden R, RStudio und Pakete geupdated?**   
David von *R for the Rest of us* hat eine wunderbare Guide zusammengestellt, wie sich R, RStudio und die Pakete auf Mac und Windows updaten lassen, ohne dass dabei Probleme entstehen (*sollten...*):

https://rfortherestofus.com/2020/09/how-to-update-rstudio-r-packages/

**Post-Tutorial: Troubleshooting!**   
Generell gilt, dass sich viele Probleme lösen lassen, indem die Dokumentation einer Funktion aufgerufen wird. Dies geht direkt in der *Console*, indem ein ? vor die Funktion gesetzt wird  (z.B.: ```?summary```).    

Da auch das nicht immer hilft, empfiehlt es sich Foren, wie bspw. [Cross Validated](https://stats.stackexchange.com) und [Stack Overflow](https://stackoverflow.com), zu durchforsten, sich mit den Regeln des Forums vertraut zu machen und bei Bedarf selbst eine Frage zu stellen.   

* Wie lese ich meine Daten ein?
  + .txt-Datei: ```txt.data <- read.delim(("Dateipfad", header = TRUE, sep = ";", dec = ",")``` (hier lässt sich bestimmen, ob die erste Zeile als Variablennamen übernommen werden soll, sowie durch welche Zeichen die Zellen getrennt sind und welches Zeichen vor Dezimalstellen verwendet wird)
  + .csv-Datei: ```csv.data <- read.csv("Dateipfad", header = TRUE, sep = ";", dec = ",")``` (hier lässt sich bestimmen, ob die erste Zeile als Variablennamen übernommen werden soll, sowie durch welche Zeichen die Zellen getrennt sind und welches Zeichen vor Dezimalstellen verwendet wird)
  + .sav-Datei: ```sav.data <- read_sav("Dateipfad")```(benötigt das Paket "haven"!)    
  
* Wie bekomme ich meine Daten ins richtige Format?
  + Umwandeln einer Variable in das Factor-, Character- oder Numeric-Format: ```as.factor(data$Variable)```, ```as.character(data$Variable)``` oder ```as.numeric(data$Variable)```   
  + Daten vom Weit- ins Langformat wandeln (Beispiel dazu im Kapitel [McNemar-Test]): mit den Funktionen ```pivot_wider()``` oder ```pivot_longer()``` 

* R sagt mir, dass meine Variable nicht vorhanden ist, was jedoch nicht stimmen kann. Was nun?    
  + Oft lohnt es sich zu überprüfen, ob noch ungewünschte Gruppierungen in den Daten vorhanden sind, die durch die Funktion ```group_by```ausgelöst wurden. Diese lassen sich mit der folgenden Funktion aufheben: ```data <- data %>% ungroup()```.    

# Setup
Diese Guide arbeitet mit exemplarischen Daten als eine Art Blaupause für eure R-Projekte. In erster Linie wird der Datensatz **sleepstudy** aus dem Paket *lme4* verwendet:   

> *"The average reaction time per day for subjects in a sleep deprivation study. On day 0 the subjects had their normal amount of sleep. Starting that night they were restricted to 3 hours of sleep per night. The observations represent the average reaction time on a series of tests given each day to each subject."* (Quelle: ```?sleepstudy```)

Zunächst müssen die Pakete geladen werden:
```{r setup, echo=T, message=F}
# Laden der Pakete "lme4", "tidyverse" und "car"
library(lme4)  # beinhaltet die "sleepstudy"-Daten & die Funktionen lmer(), glmer()
library(tidyverse) # beinhaltet u.A. ggplot2, dplyr (und andere nützliche Pakete)
library(car) # beinhaltet u.A. die Funktion leveneTest()
library(rstatix) # beinhaltet u.A. die Funktion identify_outliers()
library(lmerTest) # erweitert lme4 (berechnet u.A. p-Werte)
library(influence.ME) # wird für influencial data bei linear mixed effects models benötigt
library(emmeans) # ermöglicht pairwise comparison bei linear mixed effect models
library(MuMIn) # ermöglicht die Ausgabe von R-Squared-Werten bei linear mixed effect models
library(ggsignif) # ermöglicht manuelles Hinzufügen von Signifikanzsternen in Plots

# Sollten diese Pakete nicht installiert sein, 
# folgende Kommandos in der Konsole eintragen (ohne "#"):
# install.packages("lme4")
# install.packages("tidyverse")
# install.packages("car")
# install.packages("rstatix")
# install.packages("lmerTest")
# install.packages("influence.ME")
# install.packages("emmeans")
# install.packages("MuMIn")
# install.packages("ggsignif")
```

# Deskriptive Statistik
Das Kommando ```head()``` zeigt die ersten Zeilen eines Datensatzes und liefert so einen kurzen Überblick:
```{r sleepstudy, echo=T}
head(sleepstudy)
```

**Übersicht über die Variablentypen:** 
```{r overview, echo=T}
str(sleepstudy)
```

**Zusammenfassung der Daten:**
```{r summary, echo=T}
summary(sleepstudy)
```

Für den Zweck dieser Guide erstellen wir an dieser Stelle zusätzliche Variablen (Geschlecht, Fremdsprache, Wortflüssigkeit):  
```{r additional data, echo=T}
# Geschlecht
sleepstudy$Sex <- factor(rep(c("m","f"), each = 90))
# Fremdsprache
sleepstudy$Language <- factor(rep(c("DE", "ENG", "FRA"), each = 60))
# Wortflüssigkeit
sleepstudy <- sleepstudy %>%
  mutate(VerbalFluency = rnorm(180, 18, 2))
# Datenkopf
head(sleepstudy)
```

Wie sich neue Variablen erstellen lassen, wird im *swirl*-Tutorial behandelt. Weitere Übersichten zu diesem Thema finden sich bspw. [hier](https://datascienceplus.com/create-new-variable-in-r/) und [hier](https://www.datanovia.com/en/lessons/compute-and-add-new-variables-to-a-data-frame-in-r/).

### Weitere nützliche Funktionen für die deskriptive Statistik:

- **Arithmetisches Mittel** einer Variable: ```mean(sleepstudy$Reaction)```   
- **Median** einer Variable: ```median(sleepstudy$Reaction)```    
- **Quantile** einer Variable: ```quantile(sleepstudy$Reaction)```    
- **Summe** einer Variable: ```sum(sleepstudy$Reaction)```    
- **Standardabweichung** einer Variable: ```sd(sleepstudy$Reaction)```    
- **Anzahl** der Datenpunkte: ```nrow(sleepstudy)```  
- **Variable erstellen**: ```sleepstudy$NewVariable <- NA```    
- **Variable entfernen**: ```sleepstudy$NewVariable <- NULL```    


## z-Transformation
Eine einfache z-Transformation wird mit der Funktion ```scale()``` durchgeführt.
Da die Reaktionszeiten der sleepstudy zu verscheidenen Messzeitpunkten erhoben wurden, kalkulieren wir die z-Werte gruppiert nach Erhebungszeitpunkt ("group_by()").
```{r z transformation, echo=T}
sleepstudy <- sleepstudy %>%
  group_by(Days) %>%
  mutate(zReaction = scale(Reaction)) %>%
  ungroup()
```

## log-Transformation
Die log-Transformation wird mit der Funktion ```log()``` durchgeführt:
```{r log, echo=T}
sleepstudy$logReaction <- log(sleepstudy$Reaction)
```

## Outlier
Eine elegante Methode zum identifizieren und entfernen von Outliern bietet das Paket *rstatix*:    
Beschreibung von ```identify_outliers()``` (*rstatix* Paket):   
*Values above Q3 + 1.5xIQR or below Q1 - 1.5xIQR are considered as outliers. Values above Q3 + 3xIQR or below Q1 - 3xIQR are considered as extreme points (or extreme outliers).*    
*Q1 and Q3 are the first and third quartile, respectively. IQR is the interquartile range (IQR = Q3 - Q1).*
```{r outlier, echo=T}
# Outlier einer Variable
outliers <- sleepstudy %>%
              identify_outliers(Reaction)
# Outlier ausgeben
print(outliers)
# Outlier einer Variable, gruppiert nach einer anderen Variable
outliers_grouped <- sleepstudy %>%
                       group_by(Days) %>%
                       identify_outliers(Reaction)
# Outlier ausgeben
print(outliers_grouped)
```

**Wie entferne ich die Outlier?**
Die Anwendung der Funktion ```identify_outliers()``` auf die nach Erhebungstag (Days) gruppierten Daten ergab **acht** Outlier, wovon **sechs** als extrem eingestuft werden.
Die Outliers sind wie folgt zu entfernen:
```{r remove outliers, echo=T}
# Alle Outlier
sleep_outliers <- 
  sleepstudy[-which(sleepstudy$Reaction %in% outliers_grouped$Reaction), ]
# Nur extreme Outlier:
# Filtern
outliers_grouped_extreme <- 
  filter(outliers_grouped, is.extreme == "TRUE")
# Entfernen
sleep_outliers_extreme <-
  sleepstudy[-which(sleepstudy$Reaction %in% outliers_grouped_extreme$Reaction), ]
```

Überprüfen wir die Anzahl der Datenpunkte, um sicher zu gehen, dass die richtige Anzahl an Spalten entfernt wurde:
```{r outlier check, echo=T}
# Alle Outliers
nrow(sleepstudy) - nrow(sleep_outliers)
# Nur extreme Outliers:
nrow(sleepstudy) - nrow(sleep_outliers_extreme)
```

(Wir speicherten hier die um die Outlier reduzierten Daten in neuen Datensätzen, damit wir die alten nicht überschreiben. Wir arbeiten der Einfachheit halber mit den Daten inklusive der Outlier weiter.)

***
# Plots   
R bietet zahlreiche Möglichkeiten zur grafischen Darstellen von Daten (mit baseR oder zusätzlichen Paketen). Eines der am häufigsten verwendeten Pakete ist **ggplot2**, da es sich sehr frei gestalten lässt. Bis auf einige wenige Ausnahmen wird auch in dieser Guide "ggplot2" verwendet.    

Zunächst erstellen wir ein neues ggplot-Element mit unserem Datensatz als Argument. Dies gilt uns als Grundlage für die Plots:

```{r ggplot, echo=T}
gg_sleep <- ggplot(sleepstudy)
```

**Hinweis:**    
Es wäre ebenfalls möglich, bereits in der ```ggplot()```-Funktion die *aesthetics* (```aes()```) zu bestimmen. So müssten wir dies nicht bei jedem "geom" neu definieren, wie wir es in den folgenden Kapiteln tun. Ich denke, dass es im Rahmen dieser Guide der praktischere Ansatz ist, die *aesthetics* hier noch nicht zu bestimmen. Somit haben wir alle Variablen der Daten in unserem ```gg_sleep```-Element vorhanden. Dies ist jedoch sicher von Person zu Person und von Projekt zu Projekt unterschiedlich. Die verschiedenen Herangehensweisen scheinen unendlich und lassen viel Raum für experimentelles Herumprobieren.        
In diesem Sinne: Frohes Plotten :-)

## Histogramm   
Um ein Histogramm mit ggplot2 zu erstellen, ergänzen wir unser ggplot-Element um die Funktion ```geom_histogram()```. Als x-Aesthetic legen wir die Reaktionsdaten fest. Die y-Achse soll die relative Häufigkeit angeben. Um die absolute Häufigkeit darzustellen, würden wir "..density.." durch "..count.." ersetzen.   
Mit dem Argument ```binwidth =``` bestimmen wir die Breite der *bins*.
```{r histogram, echo=T}
# Plot speichern
sleep_hist <-
  gg_sleep + 
  geom_histogram(aes(x = Reaction, y = ..density..), 
                 binwidth = 5
                 )
# Plot ausgeben
sleep_hist
```

### Histogramm mit Normalverteilungskurve
Um unserem Plot eine Normalverteilungskurve hinzuzufügen, muss das ggplot-Element um die Funktion ```stat_function()``` mit den Argumenten ```fun = dnorm``` und ```args = list()``` ergänzt werden. Innerhalb der ```list()```-Klammer geben wir die Variable an, deren Histogramm betrachtet wird. Mit dem Argument ```col = ``` können wir bestimmen, in Welcher Farbe die Kurve abgebildet werden soll:
```{r hist distribution, echo=T}
# Normalverteilungskurve ergänzen und Plot in neuer Variable speichern
sleep_hist2 <- 
  sleep_hist + 
  stat_function(fun = dnorm, 
                args = list(mean = mean(sleepstudy$Reaction), 
                            sd = sd(sleepstudy$Reaction)),
                col = "blue"
                )
# Plotten
sleep_hist2
```

Mit der Funktion ```geom_density()``` kann zusätzlich eine geglättete Version des Histogramms hinzugefügt werden:

```{r hist density curve, echo=T}
# Geglättete Density Kurve ergänzen und in neuer Variable speichern
sleep_hist3 <- 
  sleep_hist2 + 
  geom_density(aes(x = Reaction),
               col = "red"
               )
# Plotten
sleep_hist3
```


## Barplots
Barplots lassen sich durch die Funktion ```geom_bar()``` erstellen. In der ```aes()```-Klammer werden die x- und y-Achse definiert.
Das Argument ```stat = ``` hat folgende Inputmöglichkeiten:   

- "summary" -> kalkuliert standardmäßig den Mittelwert    
- "identity" -> bildet die Daten ab, wie sie vorliegen    
- "count" -> zählt die Anzahl der Ausprägungen    

```{r barplot, echo=T}
gg_sleep + 
  geom_bar(aes(x = Days, y = Reaction), 
           stat = "summary"
           )
```

### Gestapelte Barplots
Um die Daten gruppiert darzustellen, ergänzen wir in der ```aes()```-Klammer entweder das Argument ```fill = ``` oder ```col = ```. R entstellt automatisch eine Legende für die Variable, nach der gruppiert werden soll.
Standardmäßig werden die Balken bei Gruppierungen gestapelt angeordnet:
```{r bar stacked, echo=T}
gg_sleep + 
  geom_bar(aes(x = Days, y = Reaction, fill = Sex), 
           stat = "summary"
           )
```

### Nebeneinander angeordnete Barplots    
Um die Balken nebeneinander anzuordnen muss ```position = "dodge"``` in der geom_bar()-Klammer ergänzt werden:
```{r bar dodge, echo=T}
# Plot erstellen
sleep_bar <- gg_sleep + 
              geom_bar(aes(x = Days, y = Reaction, fill = Sex), 
                      stat = "summary",
                      position = "dodge"
                      )
# Plot ausgeben
sleep_bar
```

### Barplots mit Fehlerbalken   
Um barplots mit Fehlerbalken mit ggplot zu erstellen, wird eine Funktion benötigt, die nicht in einem Paket erhalten ist. Wie dies funktioniert ist einer [Anleitung auf sthda.com](http://www.sthda.com/english/wiki/ggplot2-error-bars-quick-start-guide-r-software-and-data-visualization) entnommen:
```{r errorbar prep, echo=T, message=F}
# Erstellen der Funktion data_summary()
data_summary <- function(data, varname, groupnames){
  require(plyr)
  summary_func <- function(x, col){
    c(mean = mean(x[[col]], na.rm=TRUE),
      sd = sd(x[[col]], na.rm=TRUE))
  }
  data_sum<-ddply(data, groupnames, .fun=summary_func,
                  varname)
  data_sum <- rename(data_sum, c("mean" = varname))
 return(data_sum)
}

# Neue Datentabelle
sleep_errorbar <- 
  data_summary(sleepstudy, varname = "Reaction",
               groupnames = "Days")
# Betrachten der neuen Datentabelle
head(sleep_errorbar)
```

Die neu erstellte Datentabelle wird daraufhin zum Erstellen der Grafik verwendet:   
```{r errorbar, echo=T}
ggplot(sleep_errorbar, 
       aes(x = Days, y = Reaction)) + 
  geom_bar(aes(x = Days, y = Reaction), 
           stat = "summary") +
  geom_errorbar(aes(ymin = Reaction-sd, ymax = Reaction+sd))
```

Ein Barplot, der dies alles **kombiniert** (also gruppiert, nebeneinander & inkl. Fehlerbalken) lässt sich wie folgt erstellen:   
```{r errorbar prep 2, echo=T, message=F}
# Erstellen der neuen Datentabelle inkl. der Variable "Sex"
sleep_errorbar2 <- 
  data_summary(sleepstudy, varname = "Reaction",
               groupnames = c("Days", "Sex"))
# Betrachten der zweiten neuen Datentabelle:
head(sleep_errorbar2)
```

Plotten:    
```{r errorbar 2, echo=T}
ggplot(sleep_errorbar2, 
       aes(x = Days, y = Reaction, fill = Sex)) + 
  geom_bar(aes(x = Days, y = Reaction, fill = Sex), 
           stat = "summary",
           position = "dodge") +
  geom_errorbar(aes(ymin = Reaction-sd, ymax = Reaction+sd),
                position = "dodge")
```

## Boxplots 
Boxplots werden in ggplot mit der Funktion ```geom_boxplot()```erstellt:
```{r boxplot, echo = T}
gg_sleep + 
  geom_boxplot(aes(x = Days, y = Reaction, fill = Sex))
```
Dieser Plot stellt nicht das dar, was wir wollten, da "Days" als numerische Variable konfiguriert ist. Mit dem Befehl ```as.factor()``` oder ```as.character()``` lässt sich dies korrigieren:

```{r to_factor, echo=T}
gg_sleep + 
  geom_boxplot(aes(x = as.factor(Days), y = Reaction, fill = Sex))
```

## Scatterplots   
Für Scatterplots wird die Funktion ```geom_point()``` verwendet:    
```{r scatterplot, echo=T}
# Plot erstellen
sleep_point <- gg_sleep + 
  geom_point(aes(x = Days, y = Reaction))
# Plotten
sleep_point
```

### Regressionsgeraden 
Um eine Regressionsgerade zu ergänzen, wird die Funktion ```geom_smooth()``` verwendet.   
Ein Blick in die *Help-Page* mittels ```?geom_smooth``` liefert weitere Informationen zu den Argumenten ```method = ``` und ```se = ```.   
```{r regression, echo=T}
sleep_point + 
  geom_smooth(aes(x = Days, y = Reaction), 
              method=lm,
              se = F
              )
```

Auch hier ließen sich mit dem Argument ```fill = ``` gruppierte Regressionsgeraden erstellen.

### Interaktionsplot    
Ein Interaktionsplot lässt sich einfach mit *baseR* erstellen. Dazu werden die benötigten Variablen in folgender Reihenfolge als Argumente der Funktion ```interaction.plot()``` geschrieben:    
```interaction.plot(x-Achse, Gruppierung, y-Achse)```

```{r interaction plot, echo=T}
interaction.plot(sleepstudy$Days, sleepstudy$Sex, sleepstudy$Reaction)
```

bei geom_line group = mit angeben!
Mit ggplot sind Interaktionsplots ein wenig komplizierter. Benötigt wird die Funktion ```geom_line()```. Wichtig ist hierbei, dass die Argumente ```stat = "summary"```und ```fun = "mean"``` ergänzt werden, sowie die Gruppierung auch mit dem Argument ```group = ``` gekennzeichnet wird.    
Die Funktion ```geom_point()``` kann optional verwendet werden, um Punkte an den unterschiedlichen Ausprägungen der unabhängigen Variable auf der x-Achse anzuzeigen:
```{r interaction plot gg, echo=T}
gg_sleep + 
  geom_line(aes(x = Days, y = Reaction, col = Sex, group = Sex), 
            stat = "summary", fun = "mean"
            ) +
  geom_point(aes(x = Days, y = Reaction, col = Sex), 
            stat = "summary", fun = "mean"
            )
```


## Q-Q-Plot
Mit *baseR*:
```{r qq base, echo=T}
qqnorm(sleepstudy$Reaction)   # Punkte
qqline(sleepstudy$Reaction)   # Linie
```

Mit *ggplot*:
```{r qq gg, echo=T}
gg_sleep + 
  stat_qq(aes(sample = Reaction)) +    # Punkte
  stat_qq_line(aes(sample = Reaction)) # Linie
```

### Textplots
Um Text zu plotten werden die Funktionen ```geom_text``` oder ```geom_label```. Der Unterschied besteht darin, dass letztere zusätzlich einen Kasten um den Text generiert. Innerhalb der ```aes()```-Klammer wird das Argument ```label =``` benötigt, welches definiert, aus welcher Variable der Text entnommen werden soll.   

**Anmerkung:**
Da es sich beim Datensatz ```sleepstudy``` um Messwiederholungsdaten handelt, wäre eine Darstellung der Datenpunkte mit Text sehr unübersichtlich. Wir generieren also zunächst eine neue Tabelle, die den Mittelwert der Reaktionsszeit nach Tag und Geschlecht berechnet.    
Die Notation ```dplyr::``` wird verwendet, damit R weiß, dass die Funktionen aus dem "dplyr"-Paket verwendet werden, nicht die gleichnamigen aus dem "plyr"-Paket.
```{r text plot, echo=T}
# Tabelle täglicher means
daily_means <- sleepstudy %>%
  dplyr::group_by(Days, Sex) %>%      # Gruppiert nach Tage und Geschlecht
  dplyr::summarise(meanReaction = mean(Reaction))  # mean der Reaktionszeit berechnen 
                                                   # und in neuer Variable speichern

# Plotten
ggplot(daily_means) + 
  geom_text(aes(x = Days, y = meanReaction, label = Sex))
```

## Weitere Funktionen für Plots  
In diesem Kapitel wird dargestellt, wie *ggplot2*-Plots modifiziert werden können.    
Hierzu werden die Plots ```sleep_bar``` aus Kapitel [Nebeneinander angeordnete Barplots] und X verwendet.    
Die hier gezeigten Funktionen stellen nur einen kleinen Ausschnitt dessen dar, was mit *ggplot2* möglich ist. Außerdem gilt auch hier, dass es oft viele verschiedene Herangehensweisen gibt. Eine umfassende Guide gibt es unter anderem auf [sthda.com](http://www.sthda.com/english/wiki/ggplot2-essentials).    

**Achtung:** Eine Erweiterung des Plots in einzelnen Schritten eignet sich hier zur Darstellung der Funktionen. In der Praxis kann dies zu Problemen führen, da sich einige Funktionen gegenseitig überschreiben (z.B. ```scale_x_continuous``` und ```scale_x_reverse```, siehe Kapitel [Achsen- und Legendenbeschriftung] und [Weitere (grafische) Transformationen]).    

### Titel
Durch die Funktion ```labs()``` können der **Haupttitel** (-> ```title =```), die **Achsentitel** (-> ```x =``` & ```y = ```) und **Legendentitel** (-> ```fill = ``` & ```colour = ```) definiert werden: 
```{r title, echo=T}
# Plot erstellen
sleep_bar_title <- sleep_bar +
                    labs(title = "Reaktionszeit über Tage nach Geschlecht",
                         x = "Tage",
                         y = "Reaktionszeit (ms)",
                         fill = "Geschlecht")
# Plot ausgeben
sleep_bar_title
```

Die Form der Titel kann mit der Funktion ```theme()``` verändert werden. Ein Blick in die Help-Page (mit ```?theme```) liefert eine Übersicht der zahlreichen Möglichkeiten und deren Anwendungen.     
Ein Beispiel:

```{r title2, echo=T}
# Plot erstellen
sleep_bar_title2 <- sleep_bar_title + 
                      theme(plot.title = element_text(colour = "#65605a", # Farbe
                                                      face = "bold",      # fett
                                                      hjust = 0.5),       # zentrieren
                            axis.title.x = element_blank(),               # Titel entfernen
                            axis.text.x = element_text(angle = 45,        # Rotation
                                                       colour = "#5c818b"), # Farbe
                            legend.title = element_text(size = 15,        # Größe
                                                        colour = "#65605a") # Farbe
                            )
# Plot ausgeben
sleep_bar_title2
```


### Achsen- und Legendenbeschriftung
Die Beschriftungen der Achsen- und Legendeneinheiten lassen sich durch die Funktionen mit Präfix ```scale_``` bearbeiten.   
Numerische Variablen erfordern das Suffix ```_conituous```, Faktoren und *Characters* das Suffix ```_discrete```.  
  
Dementsprechend können wir die x-Achse, auf der die numerische Variable "Days" liegt mit der Funktion ```scale_x_continuous``` bearbeiten.   
Mit dem Argument ```breaks =``` geben wir an, an welchen Zeitpunkten eine Achsenbeschriftung vorhanden sein soll. Mit dem Argument ```labels =``` können diese noch eine neue Beschriftung erhalten.   
  
Die *breaks* der y-Achse definieren wir durch die Funktion ```seq```, wobei die erste und zweite Zahl den Bereich markieren, für welchen die Beschriftung im Abstand der dritten Zahl erfolgen.   
  
  
Die Legende, welche wir durch ```fill = Sex``` definiert haben erfordert für den Faktor "Sex" die Funktion ```scale_fill_discrete```. 

```{r plot ticks, echo=T}
# Plot erstellen
sleep_bar_axis <- sleep_bar_title2 + 
  scale_x_continuous(breaks = c(1, 5, 9),                      # Breaks bestimmen
                     labels = c("Tag 1", "Tag 5", "Tag 9")) +  # Breaks umbenennen
  scale_y_continuous(breaks = seq(0, 500, 50)) +               # Breaks alle 50 ms
  scale_fill_discrete(labels = c("weiblich", "männlich"))      # Ausprägungen umbenennen
  
# plotten
sleep_bar_axis
```

R ordnet *Factors* und *Characters* automatisch alphabetisch. Wenn diese auch in der Tabelle anders angeordnet sein sollen, müsste das bereits vor der Erstellung des *ggplot*-Objekts (in unserem Fall ```gg_sleep```) wie folgt passieren:    
```sleepstudy$Sex <- factor(sleepstudy$Sex, levels = c("m", "f"))```

### Farben
Die Farben des Plots können mithilfe der folgenden Funktionern verändert werden:    

- ```scale_fill_manual``` (wenn wir die Gruppierung über ```fill =``` erstellt haben) oder    
- ```scale_color_manual``` (wen wir die Gruppierung über ```colour =``` erstellt haben)   

Damit die Legendenbeschriftungen "weiblich" und "männlich" nicht überschrieben werden, definieren wir sie auch hier in der ```scale_fill_manual```-Klammer. Täten wir dies nicht, würden sie wieder in ihrem Ausgangsformat ("f", "m") erscheinen.
```{r plot colours, echo=T}
# Plot erstellen
sleep_bar_col <- sleep_bar_axis +
  scale_fill_manual(labels = c("weiblich", "männlich"),     # Labels
                    values = c("#eed28e", "#a14e2a")        # Farben
                    )
# Plotten
sleep_bar_col
```
  

Ungruppierte Plots lassen sich durch die Argumente ```fill =``` und ```col =``` färben. Diese Argumente stehen **nicht** in der ```aes()```-Klammer!    
Ein Beispiel, wie wir den Plot aus dem Kapitel [Barplots] ergänzen könnten:

```{r plot colours not grouped, echo=T}
gg_sleep + geom_bar(aes(x = Days, y = Reaction), 
                    stat = "summary",
                    fill = "lightblue",    # Füllung
                    col = "orange"         # Rand
                    )
```

#### Paletten
*ggplot2* verfügt über die Farbpaletten des Pakets [RColorBrewer](https://www.datanovia.com/en/blog/the-a-z-of-rcolorbrewer-palette/). Diese lassen sich mit den Funktionen ```scale_fill_brewer``` oder ```scale_colour_brewer``` abrufen - je nachdem, ob ```fill =``` und/oder ```colour =``` für die Gruppierung verwendet wurden.   
Im folgenden Beispiel wird die Palette "Pastel2" verwendet. Die *labels* werden wie bereits im Kapitel [Farben] erneut definiert, damit sie nicht überschrieben werden.

```{r bar palette, echo=T}
# Plot erstellen
sleep_bar_pal <- sleep_bar_col + 
  scale_fill_brewer(labels = c("weiblich", "männlich"),  # Labels
                    palette="Pastel2")                   # Palette
# Plotten
sleep_bar_pal
```

#### Entfärben
Die Funktionen ```scale_fill_grey``` und ```scale_colour_grey``` legen eine Palette aus verschiedenen Grautönen über die Gruppierungen:

```{r bar bw, echo=T}
# Plot erstellen
sleep_bar_bw <- sleep_bar_pal + 
  scale_fill_grey(labels = c("weiblich", "männlich"))
# Plotten
sleep_bar_bw
```


#### *Themes*
Das Aussehen der nicht-Daten komponenten lässt sich auch über sogenannte *themes* anpassen. Dies resultiert in einem einheitlichen Erscheinungsbild. Es stehen die Funktionen ```theme_grey```, ```theme_bw```, ```theme_linedraw```, ```theme_light```, ```theme_dark```, ```theme_minimal```, ```theme_classic``` & ```theme_void``` zur Verfügung.    

Die Funktion ```theme_minimal``` überschreibt hier, was wir im Kapitel [Titel] in der ```themes()```-Klammer definiert haben, weshalb der Titel der x-Achse wieder angezeigt wird, der Legendentitel in der ursprünglichen Größe vorhanden ist und der Haupttitel nicht mehr zentriert ist.
```{r bar theme, echo=T}
# Plot erstellen
sleep_bar_min <- sleep_bar_bw + 
  theme_minimal()
# Plotten
sleep_bar_min
```

### Weitere (grafische) Transformationen
  
- Achsen spiegeln: ```scale_x_reverse()``` oder ```scale_y_reverse()```     
  - **Achtung:** Überschreibt andere ```scale_```-Funktionen der jeweiligen Achse!    
- Achsen begrenzen: ```xlim(min, max)``` oder ```ylim(min, max)``` (min und max stehen für Zahlenwerte)    
- Legendenposition verändern: ```theme(legend.position = "")``` (in Anführungsstrichen ergänzen: bottom, top, right, left)

```{r plot transformation, echo=T}
# Plot erstellen
sleep_bar_trans <- sleep_bar_min +
  scale_x_reverse() +       # x-Achse spiegeln
  ylim(0, 500) +            # Grenzen der y-Achse
  theme(legend.position = "bottom")   # Position der Legende
# Plotten
sleep_bar_trans
```

### Aufgeteilte Plots
Plots lassen sich mit Hilfe der Funktion ```facet_grid()``` nach Variablen Aufteilen.
Wir verwenden hierfür wieder den farbigen Plot aus dem Kapitel [Paletten].    

**Plots aufgeteilt nach Sprache:**
```{r plot facet, echo=T}
sleep_bar_pal + 
  facet_grid(~ Language) 
```

**Plots aufgeteilt nach Sprache und Geschlecht:**
```{r plot facet 2, echo=T}
sleep_bar_pal + 
  facet_grid(Sex ~ Language) 
```

*(Dieser Plot macht in diesem Fall natürlich nur bedingt Sinn, da wir bereits nach Geschlecht farbig gruppiert haben.)*

### Formen von Punkten
Die Formen von Scatterplots, bzw. Punktediagrammen, lassen sich in *ggplot2* auf verschiedenste Arten gestalten. Eine Übersicht über die Formen gibt es auf [sthda.com](http://www.sthda.com/english/wiki/ggplot2-point-shapes).    

Es stehen die Argumente ```shape =```, ```col =```, und ```size =``` zur Verfügung. Werden diese außerhalb der ```aes()```-Klammer definiert, gilt die Formatierung für alle Punkte, und ist somit **ungruppiert:**
```{r plot shape, echo=T}
gg_sleep + 
  geom_point(aes(x = Days, y = Reaction), shape = 1, col = "red", size = 3)
```


Werden sie innerhalb der Klammer definiert, werden die Punkte nach der angegebenen Variable in ihrer Form verändert **gruppiert**:
```{r plot shape grouped, echo=T}
# Plot erstellen
sleep_point2 <- gg_sleep + 
  geom_point(aes(x = Days, y = Reaction, shape = Sex, col = Sex, size = Sex))
# Plotten
sleep_point2
```

Um die Form im nachhinein zu verändern können die Funktionen ```scale_shape_manual```, ```scale_colour_manual``` und ```scale_size_manual``` wie folgt verwendet werden:
```{r plot shape manual, echo=T}
sleep_point2 +
  scale_shape_manual(values = c(17,19)) +
  scale_colour_manual(values = c("#e9c46a", "#2a9d8f")) +
  scale_size_manual(values = c(1,2))
```

### Formen von Linien
Die Formen von Linien lassen sich durch das Argument ```linetype =```bestimmen. Es stehen folgende Möglichkeiten zur Auswahl: “blank”, “solid”, “dashed”, “dotted”, “dotdash”, “longdash”, “twodash”.    

Wie in vorherigen Beispielen zu ```shape =``` und ```fill =``` kommt es darauf an, ob ```linetype =``` innerhalb der ```aes()```-Klammer steht oder nicht. 

Steht es nicht in der Klammer gilt die Formatierung für alle Linien, und ist somit **ungruppiert:**
```{r line shape ungrouped, echo=T}
gg_sleep + 
  geom_line(aes(x = Days, y = Reaction), 
            stat = "summary", fun = "mean",
            linetype = "dotted")
```


Steht ```linetype =``` innerhalb der ```aes()```-Klammer werden die Linien nach der angegeben Variable in unterschiedlichen Linienformen **gruppiert:**
```{r line shape grouped, echo=T}
# Plot erstellen
sleep_line <- gg_sleep + 
  geom_line(aes(x = Days, y = Reaction, linetype = Sex), 
            stat = "summary", fun = "mean")
# Plotten
sleep_line
```

Um die Linienformen manuell zu verändern wird ähnlich der Beeinflussung von Farbe und Form die Funktion ```scale_linetype_manual(values = c())```.

### Text im Plot
Um Text innerhalb der Plots zu ergänzen wird die Funktion ```annotate``` verwendet:  

```{r text in plot, echo=T}
sleep_line +
  annotate(x = 2.5,       # Position auf der x-Achse
           y = 350,       # Position auf der y-Achse
           geom = "text",   # "text" oder "label"
           label = "Hier könnte dein Text stehen",  # Text
           colour = "darkblue",  # Farbe
           size = 5)             # Größe
```


### Signifikanzsterne
Signifikanzsterne lassen sich **manuell** hinzufügen. Dazu wird die Funktion ```geom_signif``` aus dem "ggpubr"-Paket verwendet. Die benötigten Argumente werden wie folgt benutzt:    

- Mit ```xmin()``` und ```xmax()``` wird angegeben, welche Punkte auf der x-Achse mit Signifikanzssternen versehen werden sollen.   
- ```y_position =``` gibt die jeweilige Position auf der y-Achse an   
- ```annotations =``` bestimmt den Text (in diesem Fall die Signifikanzsterne)    
- Die jeweiligen Stellen korrellieren nach der Stelle, an der sie stehen. Im folgenden Beispiel geben wir an, dass Tag "0" mit Tag "9" verglichen wurde und "***" auf der Höhe von y = 480 abgebildet werden soll.   

```{r plot significance, echo=T}
gg_sleep + 
  geom_boxplot(aes(x=as.factor(Days), y=Reaction)) + 
  geom_signif(aes(x=as.factor(Days), y=Reaction), 
              xmin = c("0", "4"),          # x-Werte min
              xmax = c("9", "6"),          # x-Werte max
              y_position = c(480, 450),    # y-Werte
              annotations = c("***", "*")  # Signifikanzsterne/Text
              )
```

Um signifikante Unterschiede zwischen Gruppen zu markieren, wird bei ```xmin``` und ```xmax``` der gleiche Wert angegeben. 

```{r plot significance group, echo=T}
gg_sleep + 
  geom_boxplot(aes(x=as.factor(Days), y=Reaction, fill = Sex)) + 
  geom_signif(aes(x=as.factor(Days), y=Reaction, fill = Sex), 
              xmin = c("9", "6"),          # x-Werte min
              xmax = c("9", "6"),          # x-Werte max
              y_position = c(480, 450),    # y-Werte
              annotations = c("***", "*")  # Signifikanzsterne/Text
              )
```

Signifkanzsterne können auch **automatisch** mit [ggsignif](https://const-ae.github.io/ggsignif/) oder dem Paket [ggpubr](http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/#compare-more-than-two-groups) - einer Erweiterung von "ggsignif" - ergänzt werden. Wie das geht, steht in den verlinkten Guides (evtl. wird dies hier zu einem späteren Zeitpunkt ergänzt).

### Plot speichern
**ggplots** lassen sich entweder direkt über das "Plots"-Fenster in *RStudio* speichern, oder aber mit der Funktion ```ggsave()```.     
Der folgende Beispielcode ist auskommentiert, damit nicht bei jedem *Knit* eine Datei gespeichert wird.   

**Achtung:** Ist im Ordner in dem die Datei gespeichert werden soll eine Datei mit dem gleichen Namen, wird diese überschieben, ohne das R euch warnt oder fragt.

```{r ggsave, echo=T}
# ggsave("filename.jpg", plot = sleep_point2)
```
  
Weitere Informationen:    

- In den Klammern, in denen der Dateiname definiert wird, kann auch der Pfad angegeben werden (z.B.: ```"user/documents/plots/filename.jpg"```)   
- Wird der Plot nicht mit ```plot =``` spezifiziert, speichert R automatisch den zuletzt erstellten Plot        
- Weitere Möglichkeiten (z.B. Bestimmen der Größe der Grafik) können der *Help-Page* entnommen werden (```?ggsave```)

***
# Inferenzstatistik   

### Testen der Normalverteilung   
Die Normalverteilung lässt sich mit Hilfe des Shapiro-Wilk Tests oder anhand eines Q-Q Plots überprüfen:
```{r shapiro wilk, echo=T}
# Shapiro-Wilk Test
shapiro.test(sleepstudy$Reaction)

# Visuelle Darstellung (Q-Q Plot)
qqnorm(sleepstudy$Reaction)
qqline(sleepstudy$Reaction)
```

Gruppierter Shapiro-Wilk Test mit dem *rstatix* Paket:
```{r shapiro wilk grouped, echo=T}
sleepstudy %>%
  group_by(Days) %>%  # weitere unabhängige Variablen durch Komma getrennt
  shapiro_test(Reaction)
```

### Testen der Varianzhomogenität   
Die Varianzhomogenität (auch Homoskedastizität) lässt sich mit dem Levene Test überprüfen:
```{r homoscedasticity, echo=T}
# bei einer abhängigen Variable:
leveneTest(Reaction ~ Sex, data = sleepstudy)
# bei mehreren abhängigen Variablen:
leveneTest(Reaction ~ Sex*Language, data = sleepstudy)
```

Gruppierter Levene Test mit dem *rstatix* Paket:
```{r homoscedasticity grouped, echo=T}
sleepstudy %>%
  group_by(Days) %>% # weitere unabhängige Variablen durch Komma getrennt
  levene_test(Reaction ~ Sex)
```

## Parametrische Tests    
### t-Test        
#### t-Test für unabhängige Stichproben   
Für den t-Test für unabhängige Stichproben erstellen wir hier einen Datensatz **ohne Messwiederholungen**, der nur aus den Messungen des **ersten Tages** besteht. Anschließend testen wir zur Verdeutlichung erneut, ob die Daten normalverteilt sind und ob Varianzhomogenität vorliegt.    
Der t-Test wird nach dem folgenden Schema durchgeführt:   
```t.test(dependent variable ~ independent variable, data = data)```

```{r t-test unabhängig, echo=T}
# Neuer Datensatz, nur mit Daten des ersten Tages
day1 <- 
  filter(sleepstudy, Days == "1")
# Normalverteilung
shapiro.test(day1$Reaction)
# Varianzhomogenität
leveneTest(Reaction ~ Sex, data = day1)
# t-test für unabhängige Stichproben
t.test(Reaction ~ Sex, data = day1)
```

#### t-Test für abhängige Stichproben   
Für den t-Test für abhängige Stichproben erstellen wir hier einen Datensatz mit **einer Messwiederholung**, der nur aus den Messungen des **ersten** und des **neunten Tages** besteht. Anschließend testen wir zur Verdeutlichung erneut, ob die Daten normalverteilt sind und ob Varianzhomogenität vorliegt.    
Damit R weiß, dass es sich um einen t-test für abhängige Stichproben handelt, wird in der Funktionsklammer ```paired = T``` ergänzt.

```{r t-test abhängig, echo=T}
# Neuer Datensatz, nur mit Daten des ersten und neunten Tages
day1_9 <- 
     filter(sleepstudy, Days %in% c("1", "9"))
# Normalverteilung
shapiro.test(day1_9$Reaction)
# Varianzhomogenität
# für die Funktion leveneTest() darf die unabhänigige Variable nicht numerisch sein, daher verwenden wir as.factor()
leveneTest(Reaction ~ as.factor(Days), data = day1_9)
# t-test für unabhängige Stichproben
t.test(Reaction ~ Days, data = day1_9, paired = T)
```

### Anova   
Die Tests nach Normalverteilung und Varianzhomogenität sind analog zur Darstellung in den jeweiligen Kapiteln:    

- [Testen der Normalverteilung]   
- [Testen der Varianzhomogenität]

#### Univariate einfaktorielle ANOVA    
Die univariate einfaktorielle ANOVA wird nach dem folgenden Schema durchgeführt:   
```aov(dependent variable ~ independent variable, data = data)```   
Die Ergebnisse der ANOVA erhalten wir, indem wir die ANOVA in die Funktion ```summary()``` einbetten.
```{r anova1, echo=T}
# Speichern der ANOVA in einer Variable
anova1 <- 
  aov(Reaction ~ Language, data = day1)
# Ergebnisse der ANOVA
summary(anova1)
# post-hoc Bonferroni
pairwise.t.test(day1$Reaction, day1$Language, p.adj = "bonf")
# Oder: post-hoc TukeyHSD
TukeyHSD(anova1)
```

#### Univariate multifaktorielle ANOVA    
Die univariate multifaktorielle ANOVA wird nach dem folgenden Schema durchgeführt:   
```aov(dependent variable ~ independent variable1 * independent variable2, data = data)``` 
```{r anova2, echo=T}
# Speichern der ANOVA in einer Variable
anova2 <- 
  aov(Reaction ~ Language * Sex, data = day1)
# Ergebnisse der ANOVA
summary(anova2)
# post-hoc TukeyHSD
TukeyHSD(anova2)
```

#### Multivariate einfaktorielle ANOVA    
Die univariate einfaktorielle ANOVA wird nach dem folgenden Schema durchgeführt:   
```manova(cbind(dependent variable1, dependent variable2) ~ independent variable, data = data)```
```{r manova1, echo=T}
# Speichern der MANOVA in einer Variable
manova1 <- 
  manova(cbind(Reaction, VerbalFluency) ~ Language, data = day1)
# Ergebnisse (gesamt)
summary(manova1)
# Ergebnisse (aufgeteilt nach abhängigen Variablen)
summary.aov(manova1)
```
Post-hoc Tests für Multivariate ANOVA müssen für jede Variable einzeln berechnet werden, siehe Kapitel [Univariate einfaktorielle ANOVA].

#### Multivariate multifaktorielle ANOVA    
Die univariate einfaktorielle ANOVA wird nach dem folgenden Schema durchgeführt:   
```manova(cbind(dependent variable1, dependent variable2) ~ independent variable1 * independent variable2, data = data)```
```{r manova2, echo=T}
# Speichern der MANOVA in einer Variable
manova2 <- 
  manova(cbind(Reaction, VerbalFluency) ~ Language*Sex, data = day1)
# Ergebnisse (gesamt)
summary(manova2)
# Ergebnisse (aufgeteilt nach abhängigen Variablen)
summary.aov(manova2)
```
Post-hoc Tests für Multivariate ANOVA müssen für jede Variable einzeln berechnet werden, siehe Kapitel [Univariate multifaktorielle ANOVA].

#### One-way repeated measures ANOVA    
*One-way repeated measures ANOVAs* lassen sich zwar auch gut mit *baseR*-Funktionen durchführen, allerdings möchte ich an dieser Stelle auch auf das Paket *rstatix* hinweisen.

##### mit *rstatix*   
Damit die Funktionen des *rstatix* Pakets funktionieren, dürfen sich im Datensatz nur die abhängigen Variablen im Datensatz befinden, die auch beobachtet werden sollen:
```{r requirements, echo=T}
# Nur die abhängigen Variablen, die auch benötigt werden im Datensatz:
sleepstudy2 <- 
  sleepstudy[, c("Reaction", "Subject", "Language", "Days")]
```

**Berechnung:**   
Aus der Anleitung entnommene Definitionen für die Argumente der Funktion ```anova_test()```:    

- *dv:* (numeric) dependent variable name.    
- *wid:* (factor) column name containing individuals/subjects identifier. Should be unique per individual   
- *between:* (optional) between-subject factor variables   
- *within:* (optional) within-subjects factor variables   
- *covariate:* (optional) covariate names (for ANCOVA)

```{r ranova1x, echo=T}
# Speichern der ANOVA in einer Variable
ranova1x <- anova_test(
  data = sleepstudy2, dv = Reaction, wid = Subject,
  within = Days
  )
# Ergebnisse 
get_anova_table(ranova1x)
```

**Post-Hoc Test:**    
Der post-hoc Test für *one-way repeated measures ANOVAs* mit *rstatix* wird mit Hilfe der Funktion ```pairwise_t_test()```durchgeführt:
```{r ranova1x post hoc, echo=T}
sleepstudy2 %>%
  pairwise_t_test(
    Reaction ~ Days, paired = TRUE,
    p.adjust.method = "bonferroni"
    )
```

##### mit *baseR*   

```{r ranova1, echo=T}
ranova1 <- aov(Reaction ~ Days + Error(Subject), data = sleepstudy)
summary(ranova1)
```

Der post-Hoc Test für *one-way repeated measures ANOVAs* mit *baseR* wird wie im Kapitel [Univariate einfaktorielle ANOVA] durchgeführt, jedoch ergänzen wir ```paired = TRUE```:
```{r ranova1 post hoc, echo=T}
pairwise.t.test(sleepstudy$Reaction, sleepstudy$Days, 
                p.adj = "bonf", 
                paired = TRUE)
```

#### Two-way repeated measures ANOVA    
Auch *two-way repeated measures ANOVAs* lassen sich mit *baseR*-Funktionen und *rstatix*  durchführen. Für post-hoc Tests muss in jedem Fall auf *rstatix* zurückgegriffen werden.

##### mit *rstatix*   
Auch hier gelten die Voraussetzungen, damit die Funktionen des *rstatix* Pakets funktionieren (siehe [One-way repeated measures ANOVA mit *rstatix*]).

**Berechnung:**   
Wir ergänzen hier beispielsweise den *between-subjects* Faktor "Language":
```{r ranova2x, echo=T}
# Speichern der ANOVA in einer Variable
ranova2x <- anova_test(
  data = sleepstudy2, dv = Reaction, wid = Subject,
  within = Days, between = Language
  )
# Ergebnisse
get_anova_table(ranova2x)
```

Es ließen sich auch weitere *within-* oder *between-subjects* Faktoren einbeziehen. Dies erfolgt nach dem folgenden Muster: ```within = c(Variable1, Variable2)```

**Post-Hoc-Tests**    
(vgl. https://www.datanovia.com/en/lessons/repeated-measures-anova-in-r/)   
Zunächst können in einem ersten Schritt die p-Werte des Effekts unserer unabhängigen Variable pro Zeitpunkt berechnet werden:

```{r ranova2x time, echo=T}
# Effekt der Sprache pro Tag
sleepstudy2 %>%
  group_by(Days) %>%
  anova_test(dv = Reaction, wid = Subject, between = Language) %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
```

Für die Berechnung der post-hoc Tests von two-way repeated measures ANOVAs wird im Vergleich zum Kapitel **One-way repeated measures ANOVA** [mit *rstatix*] eine Gruppierung ("group_by()") nach Messzeitpunkt vorgenommen. In der Klammer der "pairwise_t_test()"-Funktion steht unsere abhängige und die unabhängige Variable, die uns interessiert:
```{r ranova2x post hoc, echo=T}
# Pairwise comparison zwischen Sprachen pro Tag
sleepstudy2 %>%
  group_by(Days) %>%
  pairwise_t_test(
    Reaction ~ Language, paired = TRUE,
    p.adjust.method = "bonferroni"
    )
```

##### mit *baseR*   
Um eine *two-way repeated measures ANOVA* in *baseR* durchzuführen, gehen wir nach folgendem Schema vor:   
```aov(dependent variable ~ independent variable1 * independent variable2 + Error(ID/within-subject-conditions), data = data)```    
Das bedeutet: 

- unsere *independent variables* werden durch einen Asterisk getrennt   
- wir ergänzen einen Error()-Term   
- in dieser Error()-Klammer steht die Variable für unsere Subject-IDs, gefolgt von einem slash (/) und unseren *within-subjects conditions*, jedoch **nicht** den *between-subject conditions* -> In diesem Fall also **nicht** ```Error(Subject/Language*Days)```   
```{r ranova2, echo=T}
# Speichern der ANOVA in einer Variable
ranova2 <- aov(Reaction ~ Language*Days + Error(Subject/Days),
               data = sleepstudy)
# Ergebnisse
summary(ranova2)
```

Für den Post-Hoc Test müssen wir bei der two-way repeated measures ANOVA mit *baseR* auf das *rstatix* Paket zurückgreifen:
```{r ranova2 post hoc, echo=T}
sleepstudy %>%
  group_by(Days) %>%
  anova_test(dv = Reaction, wid = Subject, between = Language) %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni") 
```

## Non-parametrische Tests    

### Mann-Whitney-U Test   
Non-parametrische Alternative für [t-Test für unabhängige Stichproben].
Wir verwenden wieder die gefilterten Daten, nur mit Tag 1 (day_1) und gehen davon aus, dass unsere Reaktionszeiten nicht Normalverteilt sind.
```{r MWU, echo=T}
wilcox.test(Reaction ~ Sex, data = day1)
```

### Wilcoxon-Test   
Non-parametrische Alternative für [t-Test für abhängige Stichproben].
Wir verwenden wieder die gefilterten Daten, nur mit Tag 1 und 9 (day1_9) und gehen davon aus, dass unsere Reaktionszeiten nicht Normalverteilt sind.
```{r wilcoxon, echo=T}
wilcox.test(day1_9$Reaction, day1_9$Days)
```

### Kruskal-Wallis-Test   
Non-parametrische Alternative für [Univariate einfaktorielle ANOVA].
```{r kruskal wallis, echo=T}
kruskal.test(Reaction ~ Language, data = day1)
```

### Friedman-Test   
Non-parametrische Alternative für [One-way repeated measures ANOVA].
Wir verwenden hierfür die Funktion ```friedman_test()```aus dem *rstatix* Paket und nehmen zur Demonstration an, dass die Reaktionszeiten nicht normalverteilt sind.
```{r friedman, echo=T}
sleepstudy %>% friedman_test(Reaction ~ Days | Subject)
```
Zusätzlich zum p-Wert wird uns unter *statistic* der Chi-Quadrat Wert ausgegeben.

Post-Hoc-Tests:
```{r friedman ph, echo=T}
sleepstudy %>% 
  wilcox_test(Reaction ~ Days, 
              paired = TRUE, 
              p.adjust.method = "bonferroni")
```

### Chi-Quadrat-Test    
Der Chi-Quadrat-Test wird hier verwendet, um zu testen, ob Geschlecht und Sprache unabhängig voneinander sind.
```{r chi, echo=T}
# Kreuztabelle
table(day1$Sex, day1$Language)
# Chi-Quadrat-Test
chisq.test(day1$Sex, day1$Language)
```
Die Warnungmeldung "Chi-Quadrat-Approximation kann inkorrekt sein" deutet darauf hin, dass zu viele Zellhäufigkeiten (mehr als 20%) unter 5 liegen. Dazu schauen wir uns die erwarteten Häufigkeiten an.

```{r chi expected, echo=T}
# Erwartete Häufigkeiten
chisq.test(day1$Sex, day1$Language)$expected
```
In diesem Fall liegen alle (>20%) Zellhäufigkeiten unter 5. Es sollte also zusätzlich der [Fisher-Test] gerechnet werden.

### Fisher-Test   
Zusätzlich zum [Chi-Quadrat-Test] bei Zellhäufigkeiten unter 5.
```{r fisher, echo=T}
# Fisher-Test
fisher.test(day1$Sex, day1$Language)
```

### McNemar-Test    
Zur Veranschaulichung des McNemar-Tests verwenden wir die ```day1_9```-Daten und kreiieren eine neue Variable (*RT_Verteilung*), die angibt, ob die Reaktionszeit über oder unter dem Mittelwert liegt.
```{r RT_Verteilung, echo=T}
day1_9$RT_Verteilung <- 
  ifelse(day1_9$Reaction >= mean(day1_9$Reaction), "higher", "lower")
```

Als nächstes sind einige Schritte notwendig:
1. Alle für den McNemar-Test unwichtigen Spalten entfernen. Wir benötigen nur die Variablen "Subject", "Days" und "RT_Verteilung".
2. Die Daten mithilfe der Funktion *pivot_wider()* [tidyr] aus dem *long format* in das *wide format* umwandeln.
3. Hier haben wir ein Problem: Unsere neuen Variablen tragen die Namen der Tage (Variable "Days"), also "1" und "9". Variablennamen die nur aus Zahlen bestehen gefallen R gar nicht. Also benennen wir sie mithilfe der colnames()-Funktion um.
4. Erstellen einer Contingency-Tabelle.
5. Ausgeben der Tabelle inklusive Summen.
6. Rechnen des McNemar-Tests
```{r mcnemar, echo=T}
# Schritt 1
day1_9_mc <- day1_9[, c("Subject", "Days", "RT_Verteilung")]
# Schritt 2
day1_9_wide <- day1_9_mc %>% 
  pivot_wider(names_from = Days, 
              values_from = RT_Verteilung
              )
# Schritt 3
colnames(day1_9_wide) <- c("Subject", "Day1", "Day9")
# Schritt 4
day1_9_mcntest <- table(day1_9_wide$Day1, day1_9_wide$Day9)
# Schritt 5
addmargins(day1_9_mcntest)
# Schritt 6
mcnemar.test(day1_9_mcntest)
```
Wie wir der Tabelle entnehmen können, war die Reaktionszeit von 13 der 18 VPs an Tag 1 unter dem Mittelwert und an Tag 9 darüber, bei vier VPs blieb sie darunter und bei einer VP blieb sie darüber. Der Unterschied zwischen den beiden Tagen ist mit p < 0.001 signifkant.


## Korrelationen    
Für die grafische Untersuchung von Korrelationen empfiehlt sich ein einfacher Scatterplot mit Regressionsgerade, wie in Kapitel [Regressionsgeraden] beschrieben:
```{r correlation plot, echo=T}
gg_sleep + 
  geom_point(aes(x = VerbalFluency, y = Reaction)) +  # zu plottende Variablen
  stat_smooth(aes(x = VerbalFluency, y = Reaction),   # Regressionsgerade
              method = lm)
```

Korrelationen können mit der Funktion ```cor.test()``` nach dem folgenden Muster berechnet werden:   
```cor.test(data$x, data$y, method = "pearson")```   
  
Das Argument ```method =``` gibt an, welcher Korelationskoeffizient berechnet werden soll ("pearson", "kendall", oder "spearman").

**Ein Beispiel:**
```{r cor test, echo=T}
cor.test(sleepstudy$VerbalFluency, sleepstudy$Reaction, method = "pearson")
```

**TIPP:** Das Paket [ggpubr](http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/#compare-more-than-two-groups) beinhaltet weitere nützliche Funktionen zur grafischen Darstellung von Korrelationen. 

## General Mixed Models     
Für eine Einleitung in das Thema empfehlen sich zwei kurze Tutorials zu *Linear Models* und *Linear Mixed Effect Models* von Bodo Winter:
Tutorial 1 (Linear Models):
http://www.bodowinter.com/uploads/1/2/9/3/129362560/bw_lme_tutorial1.pdf
Tutorial 2 (Linear Mixed Effects Models):
http://www.bodowinter.com/uploads/1/2/9/3/129362560/bw_lme_tutorial2.pdf

### Linear Model    
Dieses einfache lineare Modell modelliert den Einfluss von Geschlecht auf Reaktionszeit an Tag 1.
Die Syntax in R lässt sich wie folgt verallgemeinern:
**lm(dependent variable ~ independent variable, data)**

```{r linear model, echo=T}
# Modell definieren
sleep_lm <- lm(Reaction ~ Sex, day1)
# Ausgabe mit der Funktion summary() 
summary(sleep_lm)
```


### Linear Mixed Effects Model    
Modelliert den Einfluss unserer unabhängigen Variablen auf unsere abhängige Variable unter Berücksichtigung anderer Faktoren, wie z.B. der Zwischensubjektvariabilität.

Grober Aufbau:
**dependent vairable ~ independent variable + error**

Die Syntax für die Funktion lmer() in R lässt sich wie folgt verallgemeinern:
**lmer(dependent variable ~ fixed effect1 + fixed effect2 + ... + (random effects), data)**

Wie unterscheiden sich *fixed effect* und *random effect*?
**Fixed effect:**
- systematischer und vorhersagbarer Effekt auf die Daten (z.B. der Effekt von Schlafentzug in Tagen auf Reaktionszeit)
- allen für ein Experiment definierten Ausprägungen sind vorhanden (z.B. der Einfluss einer Variable "Höflichkeit" mit den Ausprägungen "unhöflich" & "höflich" auf unsere abhängige Variable)
**Random effect:**
- kann einen Einfluss auf die Daten haben, der nicht systematisch und vorhersagbar ist (z.B. Zwischensubjektvariabilität)
- stell ein zufälliges Sample der Gesamtpopulation dar (z.B. unsere gewählten VPs, Items einer Condition etc.)

Aufbau des *random effects*:
- ```(random slope | random intercept)```
- Nur variierender Intercept (also Variation innerhalb eines random effects): ```(1|random effect)```
- Nur variierende Slope: ```(0+fixed effect|random effect)```
- Variierender Intercept & variierende Slope: ```(1+fixed effect|random effect)```

Random slope & intercept grafisch dargestellt:
http://mfviz.com/hierarchical-models/

Wollen wir berücksichtigen, dass sich die Subjects in ihrer Fähigkeit zu reagieren unterscheiden, sagen wir dem Modell, dass es **für jedes Subject einen anderen Intercept** annehmen soll:
```{r linear mixed1, echo=T}
# Modell definieren
lmm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
# Ausgabe mit der Funktion summary() 
summary(lmm1)
```
So können wir beispielsweise berücksichtigen, dass manche Subjects generell schneller reagieren können als Andere.

Wollen wir berücksichtigen, dass sich die Subjects in ihrer Fähigkeit zu reagieren **nicht** unterscheiden, sie jedoch Unterschiede aufgrund des *fixed effect* (hier: Days) aufweisen, sagen wir dem Modell, dass es **für jedes Subjekt den gleichen Intercept, jedoch eine andere Slope** annehmen soll. Wir berücksichtigen also, dass manche Subjects mehr unter dem Schlafentzug leiden als andere:
```{r linear mixed2, echo=T}
# Modell definieren
lmm2 <- lmer(Reaction ~ Days + (0+Days|Subject), sleepstudy)
# Ausgabe mit der Funktion summary() 
summary(lmm2)
```

Wollen wir berücksichtigen, dass sich die Subjects in ihrer Fähigkeit zu reagieren unterscheiden **und** sie  Unterschiede aufgrund des *fixed effect* (hier: Days) aufweisen, sagen wir dem Modell, dass es **für jedes Subject einen anderen Intercept und eine andere Slope** annehmen soll:
```{r linear mixed3, echo=T}
# Modell definieren
lmm3 <- lmer(Reaction ~ Days + (1+Days|Subject), sleepstudy)
# Ausgabe mit der Funktion summary() 
summary(lmm3)
```

Typisch wäre hier z.B. auch eine Berücksichtigung der Unterschiedlichen Items nach kritischer unabhängiger Variable (hier "Condition"): ```RT ~ Condition + (1+Condition|Item)```.

Interagierende *fixed effects* werden mit einem * verbunden: 
```fixed effect1*fixed effect2```
Dies fasst die folgenden Notation zusammen: 
```fixed effect1 + fixed effext2 + fixedeffect1:fixedeffect2```
Wobei ```fixedeffect1:fixedeffect2``` für die Interaktion zwischen den Effekten steht.


#### R-Squared
Anders als bei einem [Linear Model] gibt die Funktion ```summary()``` bei [Linear Mixed Effect Models] keine *R-Squared*-Werte (R2) aus. Um den *conditional R2* und *marginal R2* eines Modells zu erhalten, kann die Funktion ```r.squaredGLMM()``` aus dem "MuMIn"-Paket verwendet werden:

```{r r squared, echo=T}
r.squaredGLMM(lmm3)
```

Alternativ eignet sich auch die Funktion ```r2()``` aus dem "sjstats"-Paket. 


#### Likelihood Ratio Test    
Verschiedene Modelle lassen sich mit der Funktion `anova()` vergleichen, um herauszufinden, welches Modell unsere Daten besser beschreibt. Wir vergleichen hier die Modelle *lmm1* und *lmm3* aus dem Kapitel [Linear Mixed Effects Model].

Zunächst müssen wir unsere Modelle noch um das Argument `REML = FALSE` ergänzen. Wir übernehmen die Kommandos der Modelle lmm1 und lmm3 und speichern sie mit der Ergänzung unter den Namen *lmm4* und *lmm5* ab:
```{r compare models, echo=T}
# Ergänzen des REML = False Kommandos
lmm4 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy, REML = FALSE)
lmm5 <- lmer(Reaction ~ Days + (1+Days|Subject), sleepstudy, REML = FALSE)
# Likelihood ratio test
anova(lmm4, lmm5)
```

Wir sehen, dass unser Modell **lmm5** (bzw. lmm3) den niedrigeren Akaike-Informationskriterium (AIC)-Wert hat und sich signifikant vom Modell lmm1 unterscheidet. Somit hat das Modell lmm3 den besseren Fit.

Mit dieser Methode lassen sich auch Modelle vergleichen, die sich z.B. bezüglich eines weiteren *fixed effects* unterscheiden. 
Der *Likelihood ratio test* wird auf den Seiten 11-14 von Bodo Winters Tutorial 2 genauer erklärt (siehe Abschnitt [General Mixed Models])

#### Stepwise Regression    
Bei einer *Stepwise Regression* wird ausgehend von einem möglichst maximalen Modell berechnet, welche *fixed* und *random effects* die Daten am besten beschreiben.   
In R wird die Funktion ```step()``` aus dem Paket "lmerTest" wie folgt verwendet:   
1. Maximales Modell erstellen   
2. Funktion ```step()``` auf Modell anwenden und in neuer Variable speichern    
3. Ergebnisse der *Stepwise Regression* ausgeben
4. Neues Modell mit der Funktion ```get_model()``` in neuer Variable speichern    

Ein Beispiel für eine *Stepwise Regression* anhand der "ham"-Daten:   
```{r stepwise regression, echo=T}
# Schritt 1
fm <- lmer(Informed.liking ~ Product*Information*Gender*Age +
             + (1|Consumer) + (1|Consumer:Product) +
             (1|Consumer:Information),
           data = ham)
# Schritt 2
step_fm <- step(fm)
# Schritt 3
step_fm      # Display elimination results
# Schritt 4
final_fm <- get_model(step_fm)
```

Kritik an Stepwise Regression (Smith 2018):

> Stepwise regression selects explanatory variables for multiple regression models based on their statistical significance. Although it has often been criticized for the misapplication of single-step statistical tests to a multi-step procedure, stepwise regression has become popular with Big Data because it is a very efficient way of choosing a relatively small number of explanatory variables from a vast array of possibilities. The assumption is that the larger the number of possible predictors, the more useful is stepwise regression.
This paper uses Monte Carlo simulations to demonstrate that a stepwise procedure may choose nuisance variables rather than true variables and that the out-of-sample accuracy of the model may be far worse than the in-sample fit. These problems are more likely to be serious when there are a large number of potential predictors. Stepwise regression does not solve the problem of Big Data. Big Data exacerbates the problems of stepwise regression.

#### Pairwise Comparison bei Linear Mixed Effect Models   

auch ham

```{r}
fm <- lmer(Informed.liking ~ Product*Information + (1|Consumer) , data=ham)
summary(fm)
anova(fm)
emmip(fm, Product ~ Information)
fm.pw <- emmeans(fm, ~ Product * Information)
pairs(fm.pw, simple = "Product")
```


Das Paket "emmeans" ermöglicht eine *Pairwise Comparison* von linearen gemischten Modellen. 
Dies funktioniert allerdings nicht, wenn der *fixed effect* - wie "Days" in diesem Fall - numerisch definiert ist. Das Modell lmm3 lässt sich nicht mit "Days" als *factor* oder *character* ausführen, weshalb zur Veranschaulichung auf das Modell lmm1 zurückgegriffen werden muss:

```{r lmm1 factor, echo=T}
lmm1f <- lmer(Reaction ~ as.factor(Days) + (1|Subject), sleepstudy)
summary(lmm1f)
```

Wie hier zu erkennen ist, kann das Modell zwar berechnet werden, jedoch scheint R jedes Level (also jeden Tag) des *fixed effets* "Days" als einen separaten *fixed effect* anzusehen. Des Weiteren unterscheiden sich der Output von ```summary(lmm1)``` und ```summary(lmm1f)``` von einander, obwohl der Input identisch sein müsste (lediglich die Definition des *fixed effects* wurde geändert).

Nichtsdestoweniger, verwenden wir lmm1f zur Veranschaulichung der Funktionsweise von emmeans:
```{r emmeans, echo=T}
lmm1f.pw <- emmeans(lmm1f, "Days")
pairs(lmm1f.pw)
```
 
Ich habe auf stackoverflow eine Frage zu diesem Thema gestellt, die unter dem folgenden Link abgerufen werden kann:
https://stackoverflow.com/questions/65495155/pairwise-comparison-of-numeric-fixed-effect-of-linear-mixed-model
 
### Voraussetzungen für General Mixed Models    
Die Voraussetzungen für *Linear Models* und *Linear Mixed Effect Models* werden auf den Seiten 12-21 von Bodo Winters Tutorial 1 genauer erklärt (siehe Abschnitt [General Mixed Models]). Im Folgenden werden grob die Funktionen in R dargestellt:

#### Linearität   
```{r glm linearity, echo=T}
plot(fitted(lmm3), residuals(lmm3))
abline(h = 0) # horizontale Linie bei y = 0
```

Hier sehen wir lineare Daten. Nonlinear wären diese, wenn ein Kurvenmuster zu erkennen wäre.

#### Kollinearität    
Kollinearität (also Korrelation zwischen *fixed effects*) lassen sich auf verschiedene Arten und Weisen überprüfen, z.B. können die Variablen wie in Kapitel [Korrelationen] untersucht werden.

Eine weitere Methode ist das Betrachten der *variance inflation factors* (VIF). Diese Werte sollten unter einem bestimmten Grenzwert liegen. Winter (2019) setzt diesen Wert bspw. bei 10 an. 
Die Funktion ```vif()``` ist im *car*-Paket enthalten und nimmt das Modell als Argument.
Zur Demonstration erstellen wir ein Modell (lmm6), welches das Modell lmm3 um den *fixed effect* "VerbalFluency" erweitert:

```{r collineartiy, echo=T}
lmm6 <- lmer(Reaction ~ Days + VerbalFluency + (1+Days|Subject), sleepstudy)
vif(lmm6)
```
Die beiden *fixed effects* zeigen so gut wie keine Kollinearität. Dies ist nicht verwunderlich, da es sich hier bei "VerbalFluency" um eine frei erfundene und von uns generierte Variable handelt.

#### Homoskedastizität    
Die Homoskedastizität (bzw. Varianzhomogenität) kann mit Hilfe des Levene Tests überprüft werden (siehe [Varianzhomogenität]):
```{r levene lm, echo=T}
leveneTest(Reaction ~ as.factor(Days), data = sleepstudy)
```

Alternativ kann ein Residual Plot betrachten werden (siehe [Linearität]).
Beispiele für Residuals Plots mit Homoskedastizität und Heteroskedastizität sind auf den Seiten 17-18 von Bodo Winters Tutorial 1 zu finden (siehe [General Mixed Models]).

#### Normalverteilung der Residuals   
Ob die Residuals normalverteilt sind lässt sich mit einem Histogram oder einem Q-Q Plot überprüfen:
```{r normality residuals, echo=T}
# Histogramm
hist(residuals(lmm3))

# Q-Q Plot
qqnorm(residuals(lmm3))
qqline(residuals(lmm3))
```

Zudem kann der Shapiro-Wilk Test (siehe [Normalverteilung]) auf die Residuals angewendet werden:
```{r shapiro residuals, echo=T}
shapiro.test(residuals(lmm3))
```

#### Influential Data   
Genauere Informationen zu *influential data* siehe Nieuwenhuis et al. (2012) und Winter (2013-1).

##### bei Linear Models   
Entsprechend Winter (2013-1) wird die Funktion ```dfbeta()``` verwendet, welche das Lineare Modell als Argument nimmt:
```{r lm influence, echo=T}
dfbeta(sleep_lm)
```

Als Grenzwert legen wir die absolute Hälfte des Slopes fest (s. [Linear Model]):
12.05 / 2 = *6.025*.

Wie der Tabelle zu entnehmen ist, sind die Datenpunkte aus Reihe 2 und 3 als *influential data* zu betrachten, da ihr absoluter Wert größer als 6.025 ist.

Winter (2013-1) über den Umgang mit *influential data*:
*"How to proceed if you have influential data points? Well, it’s definitely not legit to simply exclude those points and report only the results on the reduced data set. A better approach would be to run the analysis with the influential points and then again without the influential points ... then you can report both analyses and state whether the interpretation of the results does or doesn’t change. The only case when it is o.k. to exclude influential points is when there’s an obvious error with them, so for example, a value that doesn’t make sense (e.g., negative age, negative height) or a value that obviously is the result due to a technical error in the data acquisition stage (e.g., voice pitch values of 0). Influence diagnostics allow you to spot those points so you can then go back to the original data and see what went wrong."*

##### bei Linear Mixed Effect Models    
Um die *influential data* bei *Linear Mixed Effect Models* zu betrachten, kann das Paket "influence.ME" von Nieuwenhuis et al. (2012) verwendet werden.
Wir untersuchen hier, ob eine VP unsere Ergebnisse potentiell verfälscht:
```{r lmem influence, echo=T}
# Influence Funktion
sleep.inf <- influence(lmm3, "Subject")
# DFBetas ausgeben
dfbetas(sleep.inf)
# DFBetas mit Cutoff plotten
plot(sleep.inf,
     which = "dfbetas",
     parameters = 2, # nur die Zweite Spalte ("Days") plotten
     xlab = "DFbetas",
     ylab = "Subject",
     cutoff = 2/sqrt(nlevels(sleepstudy$Subject))) # nach Nieuwenhuis et al. (2012)
```

Anders als Winter (2013-1) wählen Nieuwenhuis et al. (2012) den Grenzwert für die DFBeta-Werte bei 2 geteilt durch die Wurzel von n, wobei n = die Anzahl der Ausprägungen des Gruppenfaktors.
In unserem Fall: 2 geteilt durch die Wurzel von 18; 
bzw. in R: ```2/sqrt(nlevels(sleepstudy$Subject))``
**= 0.4714045**

Wie der Tabelle und dem Plot zu entnehmen sind, liegt VP 335 über diesem Wert.

Mit der Funktion ```exclude.influence()``` kann die VP 335 aus dem Modell entfernt werden:
```{r excl infl, echo=T}
# exclude.influence - Funktion
lmm3.excl <- exclude.influence(lmm3, "Subject", "335")
# Summary des neuen Modells
summary(lmm3.excl)
```

Nieuwenhuis et al. (2012) über den Umgang mit *influential data*:
*"Generally, there are several strategies, including getting more data, checking data consis- tency, adapting model specification, deleting the in- fluential cases from the model, and obtaining addi- tional measurements on existing cases to account for the overly influential cases."*

## Generalized Linear Models    
... folgen. 
Für eine erste Übersicht:
https://www.r-bloggers.com/2018/10/generalized-linear-models-understanding-the-link-function/

# Bayesian Methods    
... folgen.

# Quellen     
*Die Quellenangabe für die genutzte R Version wird mit der Funktion ```citation()```abgefragt. Für Pakete wird einfach der Name des Pakets in der Klammer in Anführungszeichen ergänzt.*   

**car:**    
John Fox and Sanford Weisberg (2019). An {R} Companion to Applied Regression, Third Edition. Thousand Oaks CA: Sage. https://socialsciences.mcmaster.ca/jfox/Books/Companion/    
**ggsignif:**   
Constantin Ahlmann-Eltze (2019). ggsignif: Significance Brackets for 'ggplot2'. R package version 0.6.0. https://CRAN.R-project.org/package=ggsignif    
**lme4:**   
Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015). Fitting Linear Mixed-Effects Models Using lme4. Journal of Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01     
**lmerTest:**   
Kuznetsova A, Brockhoff PB, Christensen RHB (2017). “lmerTest Package: Tests in Linear Mixed Effects Models.” _Journal of Statistical Software_, *82*(13), 1-26. doi: 10.18637/jss.v082.i13   
**influence.ME:**   
Rense Nieuwenhuis, Manfred te Grotenhuis and Ben Pelzer (2012). influence.ME: Tools for Detecting Influential Data in Mixed Effects Models. R Journal, 4(2): pp. 38-47.   
**MuMIn:**
Kamil Bartoń (2020). MuMIn: Multi-Model Inference. R package version 1.43.17. https://CRAN.R-project.org/package=MuMIn        
**R:**    
R Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/    
**RStudio:**
RStudio Team (2020). RStudio: Integrated Development Environment for R. RStudio, PBC, Boston, MA URL http://www.rstudio.com/.   
**rstatix:**    
Alboukadel Kassambara (2020). rstatix: Pipe-Friendly Framework for Basic Statistical Tests. R package version 0.6.0. https://CRAN.R-project.org/package=rstatix    
**tidyverse:**    
Wickham et al. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686   
  
**Weitere Literatur:**    
Smith, G. (2018). Step away from stepwise. Journal of Big Data, 5(1), 32. https://doi.org/10.1186/s40537-018-0143-6   
Winter, B. (2013-1). Linear models and linear mixed effects models in R: Tutorial 1. http://www.bodowinter.com/uploads/1/2/9/3/129362560/bw_lme_tutorial1.pdf    
Winter, B. (2013-2). A very basic tutorial for performing linear mixed effects analyses (Tutorial 2). http://www.bodowinter.com/uploads/1/2/9/3/129362560/bw_lme_tutorial2.pdf    
Winter, B. (2019). Statistics for linguists: An introduction using R. Routledge.    

***
**Diese Guide wurde zuletzt mit den folgenden Versionen getestet:**   
*Um diese Informationen abzurufen ```sessionInfo()``` in der Konsole ausführen.*   

R version 4.0.2 (2020-06-22)  
RStudio version 1.3.1073
Platform: x86_64-apple-darwin17.0 (64-bit)    
Running under: macOS  10.16   

attached base packages:   
stats, graphics, grDevices, utils, datasets, methods, base

other attached packages:    
plyr_1.8.6, emmeans_1.5.0, influence.ME_0.9-9, rstatix_0.6.0, car_3.0-9, carData_3.0-4, forcats_0.5.0, stringr_1.4.0, dplyr_1.0.2, purrr_0.3.4, readr_1.3.1, tidyr_1.1.2, tibble_3.0.4, ggplot2_3.3.2, tidyverse_1.3.0, lmerTest_3.1-2, lme4_1.1-23, Matrix_1.2-18, ggsignif_0.6.0, MuMIn_1.43.17   

***